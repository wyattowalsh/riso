# Quickstart

Welcome to **{{ project_name }}**, the baseline render produced by the Riso template.

## Prerequisites

- Python 3.11 (managed through [uv](https://github.com/astral-sh/uv))
- pnpm 8+

## Bootstrap

```bash
uv sync
uv run python -m {{ package_name }}.quickstart
make quality
# or, if make is unavailable
uv run task quality
```

The quickstart script executes pytest, ruff, mypy, and pylint. The `quality` target chains all
quality tools (linting, typing, coverage) and records durations in `.riso/quality-durations.json`
for governance evidence. The `uv run task quality` fallback relies on the bundled Taskipy
definition so environments without `make` stay aligned.

## Optional Modules

- Enable `cli_module=enabled` to scaffold a Typer CLI with Vitest smoke tests.
- Enable `api_tracks=python` or `api_tracks=node` for FastAPI or Fastify services.
- Enable `mcp_module=enabled` for FastMCP tooling.

Refer to `docs/modules/prompt-reference.md` for compatibility details.

{% if cli_module | lower == 'enabled' %}
## CLI Module Usage

Your project includes a robust Typer CLI with multi-command structure, rich formatting, and plugin support.

### Basic Commands

```bash
# Show all available commands
uv run python -m {{ package_name }}.cli --help

# Run quickstart command
uv run python -m {{ package_name }}.cli quickstart

# Show version information
uv run python -m {{ package_name }}.cli version

# Initialize configuration
uv run python -m {{ package_name }}.cli init
```

### Configuration Management

Manage persistent configuration across command executions:

```bash
# Set a configuration value
uv run python -m {{ package_name }}.cli config set api.endpoint https://api.example.com

# Get a configuration value
uv run python -m {{ package_name }}.cli config get api.endpoint

# List all configuration
uv run python -m {{ package_name }}.cli config list

# Validate configuration file
uv run python -m {{ package_name }}.cli config validate
```

Configuration precedence (highest to lowest):
1. Command-line arguments
2. Environment variables (prefix: `{{ package_name | upper }}_`)
3. Configuration file (`config.toml` or `.{{ package_slug }}.toml`)
4. Default values

### Interactive Features

Commands support interactive prompts and rich formatting:

```bash
# Commands prompt for missing parameters
uv run python -m {{ package_name }}.cli quickstart
# → Prompts: "What's your name?"

# View formatted output (tables, colors, progress bars)
uv run python -m {{ package_name }}.cli list --format table

# JSON output for scripting
uv run python -m {{ package_name }}.cli list --format json

# Verbose output for debugging
uv run python -m {{ package_name }}.cli quickstart --verbose
```

### Async Commands

Execute asynchronous operations with progress tracking:

```bash
# Fetch data asynchronously
uv run python -m {{ package_name }}.cli async fetch https://api.example.com/data

# Batch operations with concurrency control
uv run python -m {{ package_name }}.cli async batch url1 url2 url3 --max-concurrent 5

# Stream processing with progress
uv run python -m {{ package_name }}.cli async stream 100 --delay 0.1
```

### Shell Completion

Install shell completion for your CLI:

```bash
# Bash
uv run python -m {{ package_name }}.cli --install-completion bash
source ~/.bashrc

# Zsh
uv run python -m {{ package_name }}.cli --install-completion zsh
source ~/.zshrc

# Fish
uv run python -m {{ package_name }}.cli --install-completion fish
```

After installation, use `<Tab>` to autocomplete commands and options.

### Plugin Development

Extend the CLI with custom commands:

1. Create a new file in `src/{{ package_name }}/cli/plugins/`
2. Follow the pattern in `example_plugin.py`
3. Your command will be automatically discovered

Example plugin structure:

```python
import typer

def my_plugin_command() -> typer.Typer:
    app = typer.Typer(name="myplugin", help="My custom plugin")
    
    @app.command("run")
    def run(name: str = typer.Argument(..., help="Name parameter")) -> None:
        """Run my custom command."""
        print(f"Hello from plugin, {name}!")
    
    return app

app = my_plugin_command()
```

### Adding New Commands

Add a new command in under 5 minutes:

1. Create `src/{{ package_name }}/cli/commands/mycommand.py`
2. Follow this template:

```python
import typer
from {{ package_name }}.cli.core.formatter import get_console

def mycommand_command() -> typer.Typer:
    app = typer.Typer(name="mycommand", help="My command description")
    
    @app.command()
    def run(
        name: str = typer.Argument(..., help="Your name"),
        greeting: str = typer.Option("Hello", help="Greeting message"),
    ) -> None:
        """Run my command."""
        console = get_console()
        console.print(f"{greeting}, {name}!")
    
    return app

app = mycommand_command()
```

3. Your command is now available: `uv run python -m {{ package_name }}.cli mycommand`

For more details, see `docs/modules/cli.md`.
{% endif %}

{% if api_tracks | lower in ['python', 'node', 'python+node'] or docs_site | lower == 'fumadocs' %}
## Container Quickstart

Your project includes production-ready Docker support with multi-stage builds, security hardening, and health checks.

### Single Service Build

Build and run a container for your API or docs:

```bash
# Build production image
docker build -f .docker/Dockerfile --target runtime-python -t {{ project_slug }}:latest .

# Run with health checks
docker run -d -p 8000:8000 --name {{ project_slug }}-api {{ project_slug }}:latest

# Verify health
curl http://localhost:8000/health
# Expected: {"status":"healthy"}

# Check non-root execution
docker exec {{ project_slug }}-api id
# Expected: uid=1000(appuser) gid=1000(appuser)
```

### Multi-Service Orchestration

Use docker-compose to run API, database, and docs together:

```bash
# Copy environment template
cp .env.example .env

# Update credentials in .env (POSTGRES_PASSWORD, REDIS_PASSWORD)

# Start all services
docker-compose up -d

# View logs
docker-compose logs -f api-python

# Health check all services
{% if api_tracks | lower in ['python', 'python+node'] %}
curl http://localhost:8000/health  # Python API
{% endif %}
{% if api_tracks | lower in ['node', 'python+node'] %}
curl http://localhost:3000/health  # Node.js API
{% endif %}
{% if docs_site | lower == 'fumadocs' %}
curl http://localhost:3001          # Fumadocs site
{% endif %}

# Stop services
docker-compose down
```

### Development Mode

For hot-reload during development:

```bash
# Use development compose override
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up

# Source code changes reload automatically
# Python: uvicorn --reload
# Node: pnpm dev
```

### CI Testing Mode

Optimized for GitHub Actions with faster health checks and BuildKit caching:

```bash
export RISO_CI_MODE=true
docker-compose -f docker-compose.yml -f docker-compose.ci.yml up -d
```

See `docs/modules/containers.md` for architecture details, performance tuning, and troubleshooting.
{% endif %}

{% if ci_platform == 'github-actions' %}
## Continuous Integration

Your project includes automated GitHub Actions workflows for quality validation.

### Viewing CI Status

After pushing your first commit or opening a pull request:

1. Navigate to your GitHub repository
2. Click the **Actions** tab
3. View workflow runs and job status

### Required Checks

The following checks must pass before PR merge:

- **Quality Checks** (`riso-quality.yml`) - Linting, type checking, testing
{% if 'node' in api_tracks %}
- **Node.js Quality** (`riso-quality.yml`) - ESLint, TypeScript, Vitest tests
{% endif %}

### Downloading Artifacts

Test results, coverage reports, and quality logs are automatically uploaded as artifacts with 90-day retention:

1. Navigate to the **Actions** tab in your repository
2. Click on a completed workflow run
3. Scroll to the **Artifacts** section at the bottom
4. Download artifacts (e.g., `python-quality-results`, `matrix-results-py3.11-<run-id>`)
5. Extract and review locally for debugging

**Artifact Contents:**
- `test-results.xml` - JUnit XML test results
- `coverage.xml` - Coverage report in Cobertura format
- `.coverage` - Raw coverage data (SQLite)
- `quality-logs/` - Ruff, mypy, pylint outputs

**Command Line Download:**
```bash
# Download all artifacts from latest run
gh run download --repo owner/repo

# Download specific artifact by name
gh run download <run-id> --name python-quality-results
```

Artifacts expire after 90 days per GitHub Actions retention policy.

### Branch Protection Setup

To enforce quality checks before merging, configure branch protection rules:

1. Navigate to **Settings** → **Branches** in your GitHub repository
2. Click **Add branch protection rule**
3. In **Branch name pattern**, enter `main` (or your default branch)
4. Enable **Require status checks to pass before merging**
5. Search for and select these required checks:
   - `python-quality` (main quality suite)
   {% if python_versions %}
   {% for version in python_versions %}
   - `python-matrix / test-py{{ version }}` (Python {{ version }} compatibility)
   {% endfor %}
   - `matrix-summary` (overall matrix status - blocks merge if any version fails)
   {% endif %}
   {% if 'node' in api_tracks %}
   - `node-quality` (Node.js quality checks)
   {% endif %}
6. Optional: Enable **Require branches to be up to date before merging** for stricter validation
7. Optional: Enable **Require linear history** to maintain clean commit history
8. Click **Create** or **Save changes**

**Verification:**

After setup, try creating a test PR with failing code:

```python
# Add to any Python file
def broken_function():  # Missing type hints, will fail mypy
    return "test"
```

Push and observe that the PR cannot be merged until quality checks pass.

**Quick Setup (GitHub CLI):**

```bash
# Requires GitHub CLI (gh) authenticated
gh api repos/{owner}/{repo}/branches/main/protection \
  --method PUT \
  --field required_status_checks[strict]=true \
  --field required_status_checks[contexts][]=python-quality \
  {% if python_versions %}
  {% for version in python_versions %}
  --field required_status_checks[contexts][]=python-matrix/test-py{{ version }} \
  {% endfor %}
  --field required_status_checks[contexts][]=matrix-summary \
  {% endif %}
  {% if 'node' in api_tracks %}
  --field required_status_checks[contexts][]=node-quality \
  {% endif %}
  --field enforce_admins=true
```

### Debugging Failures

**Linting Failure:**
```
❌ Quality Checks > Run quality checks > ruff check
Error: Ruff found 3 issue(s)
```
Fix the reported issues and push again.

**Type Checking Failure:**
```
❌ Quality Checks > Run type checking
Error: mypy found 1 error
```
Correct type mismatches and verify locally with `uv run mypy .`

**Cache Issues:**

If CI is consistently slow (>6 minutes), check cache hit status in workflow logs:

**Cache Hit (good):**
```
Cache restored from key: ubuntu-latest-py3.11-abc123def456
```

**Cache Miss (investigating):**
```
Cache miss - no matching cache key found
```

**Troubleshooting Steps:**

1. **Verify lock file is committed:**
   ```bash
   git ls-files | grep -E '(uv.lock|pnpm-lock.yaml)'
   ```
   Missing lock files prevent cache key generation.

2. **Check for lock file changes:**
   ```bash
   git diff HEAD~1 HEAD -- uv.lock
   ```
   If lock file changes frequently, cache won't hit.

3. **Inspect cache key in workflow logs:**
   Look for "Post Cache dependencies" step to see the actual key used.

4. **Clear GitHub Actions cache manually:**
   Settings → Actions → Caches → Delete specific cache

5. **Verify cache size:**
   Caches >5GB may fail to restore. Run `du -sh ~/.cache/uv` locally to estimate.

**Expected Performance:**
- First run (cache miss): 5-6 minutes
- Subsequent runs (cache hit): 2-3 minutes
- Cache hit rate target: ≥70%

See `docs/modules/workflows.md` for advanced cache debugging.

{% if api_tracks | lower in ['python', 'node', 'python+node'] or docs_site | lower == 'fumadocs' %}
### Container Debugging

**Build Failures:**

```bash
# Validate Dockerfiles with hadolint
docker run --rm -i hadolint/hadolint < .docker/Dockerfile

# Check lock files are committed
git ls-files | grep -E '(uv.lock|pnpm-lock.yaml)'
```

**Health Check Failures:**

```bash
# Check container logs
docker logs {{ project_slug }}-api

# Manual health test inside container
docker exec {{ project_slug }}-api curl http://localhost:8000/health
```

**Permission Errors:**

```bash
# Fix ownership (files created by root)
sudo chown -R 1000:1000 .
```

See `docs/modules/containers.md` for detailed troubleshooting.
{% endif %}

For more details, see `docs/modules/workflows.md`.
{% endif %}
