{% if codegen_module == 'enabled' %}"""Template caching for offline usage and performance.

This module manages local template caching, version tracking, and
cache operations (update, clear, list).
"""

from pathlib import Path
from datetime import datetime
from typing import Optional
import shutil
import hashlib
import json
from loguru import logger


class CacheManager:
    """Manage template cache for offline usage."""
    
    def __init__(self, cache_dir: Optional[Path] = None):
        """Initialize cache manager.
        
        Args:
            cache_dir: Cache directory (default: ~/.scaffold/templates)
        """
        if cache_dir is None:
            cache_dir = Path.home() / ".scaffold" / "templates"
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Version cache for update support
        self.version_cache_dir = Path.home() / ".scaffold" / "cache" / "versions"
        self.version_cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.debug(f"Cache manager initialized: {cache_dir}")
    
    def cache_template(
        self,
        source_path: Path,
        template_name: str,
        version: str,
    ) -> Path:
        """Cache a template from source.
        
        Args:
            source_path: Source template directory
            template_name: Template name
            version: Template version
            
        Returns:
            Path to cached template
        """
        dest_path = self.cache_dir / template_name
        
        # Remove existing cache
        if dest_path.exists():
            logger.debug(f"Removing existing cache: {dest_path}")
            shutil.rmtree(dest_path)
        
        # Copy template to cache
        shutil.copytree(source_path, dest_path)
        
        # Store version cache for updates
        version_path = self.version_cache_dir / template_name / version
        version_path.mkdir(parents=True, exist_ok=True)
        shutil.copytree(source_path, version_path, dirs_exist_ok=True)
        
        # Create cache metadata
        metadata = {
            "template_name": template_name,
            "version": version,
            "cached_at": datetime.now().isoformat(),
            "checksum": self._calculate_checksum(dest_path),
        }
        metadata_file = dest_path / ".cache-metadata.json"
        with open(metadata_file, "w") as f:
            json.dump(metadata, f, indent=2)
        
        logger.info(f"Cached template '{template_name}' v{version}")
        return dest_path
    
    def get_cached_template(self, template_name: str) -> Optional[Path]:
        """Get cached template path.
        
        Args:
            template_name: Template name
            
        Returns:
            Path to cached template or None if not cached
        """
        template_path = self.cache_dir / template_name
        if template_path.exists() and (template_path / "template.yml").exists():
            return template_path
        return None
    
    def get_base_version(self, template_name: str, version: str) -> Optional[Path]:
        """Get base version for three-way merge.
        
        Args:
            template_name: Template name
            version: Version to retrieve
            
        Returns:
            Path to base version or None if not found
        """
        version_path = self.version_cache_dir / template_name / version
        if version_path.exists():
            return version_path
        return None
    
    def list_cached_templates(self) -> list[dict]:
        """List all cached templates with metadata.
        
        Returns:
            List of cache metadata dictionaries
        """
        cached = []
        for template_dir in self.cache_dir.iterdir():
            if not template_dir.is_dir():
                continue
            
            metadata_file = template_dir / ".cache-metadata.json"
            if metadata_file.exists():
                with open(metadata_file) as f:
                    metadata = json.load(f)
                cached.append(metadata)
            else:
                # No metadata, just basic info
                cached.append({
                    "template_name": template_dir.name,
                    "version": "unknown",
                    "cached_at": None,
                })
        
        return cached
    
    def clear_cache(self, template_name: Optional[str] = None) -> int:
        """Clear template cache.
        
        Args:
            template_name: Specific template to clear, or None for all
            
        Returns:
            Number of templates cleared
        """
        if template_name:
            template_path = self.cache_dir / template_name
            if template_path.exists():
                shutil.rmtree(template_path)
                logger.info(f"Cleared cache for '{template_name}'")
                return 1
            return 0
        else:
            # Clear all cache
            count = 0
            for template_dir in self.cache_dir.iterdir():
                if template_dir.is_dir():
                    shutil.rmtree(template_dir)
                    count += 1
            logger.info(f"Cleared cache for {count} templates")
            return count
    
    def validate_cache_integrity(self, template_name: str) -> bool:
        """Validate cache integrity using checksums.
        
        Args:
            template_name: Template to validate
            
        Returns:
            True if cache is valid, False if corrupted
        """
        template_path = self.cache_dir / template_name
        metadata_file = template_path / ".cache-metadata.json"
        
        if not metadata_file.exists():
            logger.warning(f"No cache metadata for '{template_name}'")
            return False
        
        with open(metadata_file) as f:
            metadata = json.load(f)
        
        expected_checksum = metadata.get("checksum")
        if not expected_checksum:
            logger.warning(f"No checksum in metadata for '{template_name}'")
            return False
        
        actual_checksum = self._calculate_checksum(template_path)
        is_valid = expected_checksum == actual_checksum
        
        if not is_valid:
            logger.error(
                f"Cache corruption detected for '{template_name}': "
                f"expected {expected_checksum}, got {actual_checksum}"
            )
        
        return is_valid
    
    def _calculate_checksum(self, directory: Path) -> str:
        """Calculate checksum for directory contents.
        
        Args:
            directory: Directory to hash
            
        Returns:
            SHA256 hex digest
        """
        hasher = hashlib.sha256()
        
        # Sort files for deterministic hashing
        files = sorted(directory.rglob("*"))
        for file_path in files:
            if file_path.is_file() and file_path.name != ".cache-metadata.json":
                hasher.update(str(file_path.relative_to(directory)).encode())
                hasher.update(file_path.read_bytes())
        
        return hasher.hexdigest()
{% endif %}