---
LIBRARY: Delgan/loguru
SOURCE_ROOT: https://github.com/Delgan/loguru/blob/master
UPDATED_AT: September 7, 2025 at 5:35 PM UTC
---

================================
CODE SNIPPETS
================================

TITLE: Replacing Standard Logger Objects with Loguru Sinks
DESCRIPTION: Demonstrates how to replace standard `Logger` objects with Loguru's `sink` configuration, using `add` to parametrize handlers and `bind` for fine-grained control over specific loggers. This allows for filtering messages based on `level`, `filter` parameters, and `record["extra"]` dict, enabling more targeted logging and message differentiation.
SOURCE: /docs/resources/migration.rst

```plaintext

## Replacing `Logger` objects

Loguru replaces the standard {{ Logger }} configuration by a proper {ref}`sink <sink>` definition. Instead of configuring a logger, you should {{ add }} and parametrize your handlers. The {{ logger.setLevel }} and {{ logger.addFilter }} are suppressed by the configured sink `level` and `filter` parameters. The {{ propagate }} attribute and {{ disable }} function can be replaced by the `filter` option too. The {{ makeRecord }} method can be replaced using the `record["extra"]` dict.  
Sometimes, more fine-grained control is required over a particular logger. In such case, Loguru provides the {{ bind }} method which can be in particular used to generate a specifically named logger.  
For example, by calling `other_logger = logger.bind(name="other")`, each {ref}`message <message>` logged using `other_logger` will populate the `record["extra"]` dict with the `name` value, while using `logger` won't. This permits differentiating logs from `logger` or `other_logger` from within your sink or filter function.  
Let suppose you want a sink to log only some very specific messages:  
def specific_only(record):
return "specific" in record["extra"]

logger.add("specific.log", filter=specific_only)

specific_logger = logger.bind(specific=True)

logger.info("General message")          # This is filtered-out by the specific sink
specific_logger.info("Module message")  # This is accepted by the specific sink (and others)
```

```plaintext
# Only write messages from "a" logger
logger.add("a.log", filter=lambda record: record["extra"].get("name") == "a")
# Only write messages from "b" logger
logger.add("b.log", filter=lambda record: record["extra"].get("name") == "b")

logger_a = logger.bind(name="a")
logger_b = logger.bind(name="b")

logger_a.info("Message A")
logger_b.info("Message B")
```

---
TITLE: Avoiding Duplicate Log Output on Terminal with Loguru
DESCRIPTION: Demonstrates how to prevent duplicate log messages when adding custom handlers to the Loguru logger. The default handler, which writes to `sys.stderr`, should be removed using `logger.remove()` before adding a new handler to avoid redundant output.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Avoiding logs to be printed twice on the terminal

The logger is pre-configured for convenience with a default handler which writes messages to {{ sys.stderr }}. You should {{ remove }} it first if you plan to {{ add }} another handler logging messages to the console, otherwise you may end up with duplicated logs.  
```

---
TITLE: Handling UnicodeEncodeError and Encoding Issues in Loguru
DESCRIPTION: Illustrates how to resolve `UnicodeEncodeError` when logging with Loguru by configuring handler encodings. Explains how to handle encoding issues when writing to `stdout` or files, including using `sys.stderr`, setting the `PYTHONIOENCODING` environment variable, or using the `encoding` parameter in `logger.add()`.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Resolving `UnicodeEncodeError` and other encoding issues

When you write a log message, the handler may need to encode the received [unicode] string to a specific sequence of bytes. The `encoding` used to perform this operation varies depending on the sink type and your environment. Problem may occur if you try to write a character which is not supported by the handler `encoding`. In such case, it's likely that Python will raise an {{ UnicodeEncodeError }}.  
For example, this may happen while printing to the terminal:  
print("天")
# UnicodeEncodeError: 'charmap' codec can't encode character '\u5929' in position 0: character maps to <undefined>
```

---
TITLE: Replacing LogRecord Objects with Loguru Record Dictionaries
DESCRIPTION: Illustrates how to replace `LogRecord` objects from standard logging with Loguru's record dictionaries. Demonstrates accessing contextual information from logged messages using the `record` attribute and extending the record dictionary with custom information using the `patch` method, providing a flexible alternative to `setLogRecordFactory`.
SOURCE: /docs/resources/migration.rst

```plaintext

## Replacing `LogRecord` objects

In Loguru, the equivalence of a {{ LogRecord }} instance is a simple `dict` which stores the details of a logged message. To find the correspondence with {{ LogRecord }} attributes, please refer to {ref}`the "record dict" documentation <record>` which lists all available keys.  
This `dict` is attached to each {ref}`logged message <message>` through a special `record` attribute of the `str`-like object received by sinks. For example:  
def simple_sink(message):
# A simple sink can use "message" as a basic string and ignore the "record" attribute.
print(message, end="")

def advanced_sink(message):
# An advanced sink can use the "record" attribute to access contextual information.
record = message.record

if record["level"].no >= 50:
file_path = record["file"].path
print(f"Critical error in {file_path}", end="", file=sys.stderr)
else:
print(message, end="")

logger.add(simple_sink)
logger.add(advanced_sink)
```

---
TITLE: Customizing Exception Formatting with Loguru Handlers
DESCRIPTION: Demonstrates customizing exception formatting in Loguru by adding a handler with a custom `format` function. This allows developers to personalize the traceback output, for example, by integrating with libraries like `stackprinter` to provide more detailed and annotated error information, enhancing debugging and error analysis.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Customizing the formatting of exceptions

Loguru will automatically add the traceback of occurring exception while using `logger.exception()` or `logger.opt(exception=True)`:  
def inverse(x):
try:
1 / x
except ZeroDivisionError:
logger.exception("Oups...")

if __name__ == "__main__":
inverse(0)
```

```none
2019-11-15 10:01:13.703 | ERROR    | __main__:inverse:8 - Oups...
Traceback (most recent call last):
File "foo.py", line 6, in inverse
1 / x
ZeroDivisionError: division by zero
```

```plaintext
If the handler is added with `diagnose=True`, then the traceback is annotated to see what caused the problem:  

File "foo.py", line 6, in inverse
1 / x
└ 0

ZeroDivisionError: division by zero
```

---
TITLE: Configuring and Using the Loguru Logger
DESCRIPTION: Demonstrates how to configure the global `logger` object provided by Loguru, including removing the default handler and adding custom handlers with specific formats and destinations like `sys.stderr` and files. This allows developers to customize log output based on their application's needs, rotating log files and setting different log levels.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## How do I create and configure a logger?

Loguru differs from standard logging as you don't need to create a logger. It is directly provided by Loguru, and you should just import it:  
```

```plaintext
This {{ Logger }} object is unique and shared across all modules of your application. Import it into every file where you need to use it. It acts as a basic facade interface around a list of handlers. These handlers are responsible for receiving log messages, formatting them, and logging them to one or more desired destinations (file, console, etc.).  
When you first import Loguru's logger, it comes pre-configured with a default handler that displays your logs on the standard error output ({{ sys.stderr }}). However, you can easily change the logger's configuration to suit your needs. First, use {{ remove }} to discard the default handler. Then, use {{ add }} to register one or more handlers that will log messages to the desired destinations. For example:  
```

---
TITLE: Troubleshooting Log Display Issues in Loguru
DESCRIPTION: Explains why logs might not be showing up when using the Loguru library. Demonstrates how to check configured sinks using `print(logger)` and how the `level` parameter in `logger.add()` affects log visibility, ensuring messages are displayed based on their severity.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## Why are my logs not showing up?

Ensure that you've added at least one sink using {{ add }}. You can get an overview of the configured handlers by simply printing the logger object:  
```

```plaintext
Check also the logging level: messages below the set level won't appear:  
```

---
TITLE: Preventing Log Duplication with Loguru Handlers
DESCRIPTION: Explains how to prevent log duplication in Loguru by removing the default handler before adding new ones using `logger.remove()` and `logger.add()`. It also highlights the importance of configuring the `logger` only once, especially when using `multiprocessing`, and avoiding duplicate handlers with the same sink unless using mutually exclusive `filter` functions.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## Why are my logs duplicated in the output?

Remember that the initial `logger` has a default handler for convenience. If you plan to change the logging configuration, make sure to {{ remove }} this default handler before to {{ add }} a new one. Otherwise, messages will be duplicated because they will be sent to both the default handler and your new handler:  
# Replace the default handler with a new one.
logger.remove()
logger.add(sys.stderr, format="{time} - {level} - {message}")
```

---
TITLE: Catching Exceptions Within Threads Using Loguru
DESCRIPTION: Demonstrates how to use the `@logger.catch` decorator to automatically catch and log exceptions occurring within threads or the main program, preventing unexpected crashes and ensuring errors are properly handled and propagated to the `logger`. This is beneficial for debugging and maintaining application stability by providing comprehensive error logging.
SOURCE: /README.md

```python
@logger.catch
def my_function(x, y, z):
# An error? It's caught anyway!
return 1 / (x + y + z)
```

---
TITLE: Typing Loguru for Static Analysis and IDE Support
DESCRIPTION: Illustrates how to use type hints with Loguru, leveraging stub files and postponed evaluation of annotations for static analysis with tools like `mypy`. Explains the available Loguru internal types such as `Logger`, `Message`, `Record`, and `Level`, and introduces the `loguru-mypy` plugin for catching potential runtime errors.
SOURCE: /docs/api/type_hints.rst

```python
from __future__ import annotations

import loguru
from loguru import logger

def good_sink(message: loguru.Message):
print("My name is", message.record["name"])

def bad_filter(record: loguru.Record):
return record["invalid"]

logger.add(good_sink, filter=bad_filter)
```

```plaintext
$ mypy test.py
test.py:8: error: TypedDict "Record" has no key 'invalid'
Found 1 error in 1 file (checked 1 source file)
```

```plaintext
pip install loguru-mypy
```

---
TITLE: Replacing `caplog` Fixture When Switching to Loguru
DESCRIPTION: Demonstrates how to replace the `caplog` fixture from `pytest` when migrating from standard logging to `loguru`. This involves overriding the `caplog` fixture in `conftest.py` to capture the handler and propagate `loguru` logs, ensuring that tests relying on captured logging output continue to function correctly.
SOURCE: /docs/resources/migration.rst

```plaintext

## Replacing `caplog` fixture from `pytest` library

[pytest] is a very common testing framework. The [caplog] fixture captures logging output so that it can be tested against. For example:  
```

```plaintext
If you've followed all the migration guidelines thus far, you'll notice that this test will fail. This is because [pytest] links to the standard library's `logging` module.  
So to fix things, we need to add a sink that propagates Loguru to the caplog handler.
This is done by overriding the [caplog] fixture to capture its handler. In your `conftest.py` file, add the following:  
```

```plaintext
Run your tests and things should all be working as expected. Additional information can be found in [GH#59] and [GH#474]. You can also install and use the [pytest-loguru] package created by [@mcarans].  
Note that if you want Loguru logs to be propagated to Pytest terminal reporter, you can do so by overriding the `reportlog` fixture as follows:  
from loguru import logger

@pytest.fixture
def reportlog(pytestconfig):
logging_plugin = pytestconfig.pluginmanager.getplugin("logging-plugin")
handler_id = logger.add(logging_plugin.report_handler, format="{message}")
yield
logger.remove(handler_id)
```

---
TITLE: Configuring Loguru for Scripts and Libraries
DESCRIPTION: Illustrates how to configure the `loguru` logger for both scripts and libraries, emphasizing the use of `configure()` for scripts and `disable()`/`enable()` for libraries to prevent conflicts. Demonstrates how to use `loguru-config` to set up the logger from a configuration file.
SOURCE: /README.md

```python
# For scripts
config = {
"handlers": [
{"sink": sys.stdout, "format": "{time} - {message}"},
{"sink": "file.log", "serialize": True},
],
"extra": {"user": "someone"}
}
logger.configure(**config)

# For libraries, should be your library's `__name__`
logger.disable("my_library")
logger.info("No matter added sinks, this message is not displayed")

# In your application, enable the logger in the library
logger.enable("my_library")
logger.info("This message however is propagated to the sinks")
```

---
TITLE: Implementing File Logging with Rotation, Retention, Compression
DESCRIPTION: Demonstrates how to configure file logging with automatic rotation based on size or time using `logger.add()`. It also illustrates how to implement log retention policies to remove older logs and compress log files using the `rotation`, `retention`, and `compression` parameters for efficient storage management.
SOURCE: /README.md

```python
logger.add("file_{time}.log")
```

```python
logger.add("file_1.log", rotation="500 MB")    # Automatically rotate too big file
logger.add("file_2.log", rotation="12:00")     # New file is created each day at noon
logger.add("file_3.log", rotation="1 week")    # Once the file is too old, it's rotated

logger.add("file_X.log", retention="10 days")  # Cleanup after some time

logger.add("file_Y.log", compression="zip")    # Save some loved space
```

---
TITLE: Using `enqueue` for Multiprocessing Compatibility with Loguru
DESCRIPTION: Demonstrates how to use the `enqueue` argument in Loguru to ensure compatibility with `multiprocessing`. This is useful when logging from multiple processes to avoid race conditions and ensure that log messages are written correctly to the `file.log`.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Compatibility with `multiprocessing` using `enqueue` argument

```

---
TITLE: Implementing Exhaustive Notifications with Apprise and Loguru
DESCRIPTION: Demonstrates how to integrate the `apprise` library with `loguru` to send notifications on errors. This allows for alerting when a program fails unexpectedly, using services like Discord, and can be further simplified with the `logprise` library.
SOURCE: /README.md

```python
import apprise

# Define the configuration constants.
WEBHOOK_ID = "123456790"
WEBHOOK_TOKEN = "abc123def456"

# Prepare the object to send Discord notifications.
notifier = apprise.Apprise()
notifier.add(f"discord://{WEBHOOK_ID}/{WEBHOOK_TOKEN}")

# Install a handler to be alerted on each error.
# You can filter out logs from "apprise" itself to avoid recursive calls.
logger.add(notifier.notify, level="ERROR", filter={"apprise": False})
```

---
TITLE: Using ZMQ for Inter-Process Logging with Loguru
DESCRIPTION: Demonstrates using the `zmq` library to implement inter-process communication for logging with `Loguru`. This recipe shows how to set up a server and client to exchange log messages, enabling centralized logging from multiple processes.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Using ZMQ to send and receive log messages

Third-party libraries like [zmq] can be leveraged to exchange messages between multiple processes. Here is an example of a basic server and client:  
```

```plaintext
```
# server.py
import sys
import zmq
from loguru import logger

socket = zmq.Context().socket(zmq.SUB)
socket.bind("tcp://127.0.0.1:12345")
socket.subscribe("")

logger.configure(handlers=[{"sink": sys.stderr, "format": "{message}"}])

while True:
_, message = socket.recv_multipart()
logger.info(message.decode("utf8").strip())
```

---
TITLE: Parsing Logs with Loguru's `parse()` Method
DESCRIPTION: Demonstrates how to use Loguru's `parse()` method to extract specific information from log files using regular expressions with named groups and type casting via a dictionary; this is useful for analyzing and processing log data programmatically.
SOURCE: /README.md

```python
pattern = r"(?P<time>.*) - (?P<level>[0-9]+) - (?P<message>.*)"  # Regex with named groups
caster_dict = dict(time=dateutil.parser.parse, level=int)        # Transform matching groups

for groups in logger.parse("file.log", pattern, cast=caster_dict):
print("Parsed:", groups)
# {"level": 30, "message": "Log example", "time": datetime(2018, 12, 09, 11, 23, 55)}
```

---
TITLE: Replacing `isEnabledFor()` with Loguru's `opt(lazy=True)`
DESCRIPTION: Demonstrates replacing the standard logging's `isEnabledFor()` method with Loguru's `opt(lazy=True)` for conditional logging. This approach avoids performance penalties by deferring the execution of expensive functions until the log message is actually needed, improving efficiency when debug logging is enabled.
SOURCE: /docs/resources/migration.rst

```plaintext

## Replacing `isEnabledFor()` method

If you wish to log useful information for your debug logs, but don't want to pay the performance penalty in release mode while no debug handler is configured, standard logging provides the {{ isEnabledFor }} method:  
```

```plaintext
You can replace this with the {{ opt }} method and `lazy` option:  
# Arguments should be functions which will be called if needed
logger.opt(lazy=True).debug("Message data: {}", expensive_func)
```

---
TITLE: Handling Modules with Missing `__name__` in Loguru
DESCRIPTION: Demonstrates how to handle modules where the `__name__` attribute is absent, causing Loguru to assign `None` to the `record["name"]`. Explains how to disable logging from such modules using `logger.disable(None)` and how to patch the `record["name"]` value using `logger.patch` to ensure correct identification in log messages.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Circumventing modules whose `__name__` value is absent

Loguru makes use of the global variable `__name__` to determine from where the logged message is coming from. However, it may happen in very specific situation (like some Dask distributed environment) that this value is not set. In such case, Loguru will use `None` to make up for the lack of the value. This implies that if you want to {{ disable }} messages coming from such special module, you have to explicitly call `logger.disable(None)`.  
Similar considerations should be taken into account while dealing with the `filter` attribute. As `__name__` is missing, Loguru will assign the `None` value to the `record["name"]` entry. It also means that once formatted in your log messages, the `{name}` token will be equals to `"None"`. This can be worked around by manually overriding the `record["name"]` value using {{ patch }} from inside the faulty module:  
# If Loguru fails to retrieve the proper "name" value, assign it manually
logger = logger.patch(lambda record: record.update(name="my_module"))
```

---
TITLE: Troubleshooting Log Colorization in Loguru
DESCRIPTION: Explains why Loguru logs might not be colored, covering automatic color detection, terminal support via `isatty`, and the impact of environment variables like `NO_COLOR`. Demonstrates how to force colorization using the `colorize` argument in `logger.add()` and how to handle raw ANSI sequences.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## Why are my logs not colored?

Log colors are configured using {ref}`special tags <color>` in the `format` of the handlers. If you use a custom `format`, make sure that these tags are included, for example:  
logger.add(sys.stderr, format="<green>{time}</green> | <level>{message}</level>")
```

```plaintext
logger.add(sys.stderr)  # Can be colored.
logger.add("file.log")  # Cannot be colored.
```

```bash
python my_script.py > output.log  # Colors will be disabled.
```

---
TITLE: Preserving `opt()` Parameters Globally in Loguru Modules
DESCRIPTION: Demonstrates how to preserve `opt()` parameters, such as `colors=True`, for an entire module in Loguru by patching the `logger.opt` method using `functools.partial`. This avoids repetitive calls to `logger.opt()` and ensures consistent logging configurations throughout the module.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Preserving an `opt()` parameter for the whole module

Supposing you wish to color each of your log messages without having to call `logger.opt(colors=True)` every time, you can add this at the very beginning of your module:  
logger = logger.opt(colors=True)

logger.info("It <green>works</>!")
```

---
TITLE: Including Exceptions in Loguru Formatted Messages
DESCRIPTION: Explains how to include exception information in Loguru log messages when using custom formatters. Demonstrates the importance of including the `"{exception}"` placeholder in the log format to ensure exception details are displayed when using `logger.exception()` or `logger.opt(exception=True)`.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## Why is the captured exception missing from the formatted message?

When `logger.exception()` or `logger.opt(exception=True)` is used within an `except` clause, Loguru automatically captures the exception information and includes it in {ref}`the logged message <message>`.  
The position of the exception in the message is controlled by the `"{exception}"` field of the configured log format. By default, when the `format` argument of {{ add }} is a string, the `"{exception}"` field is automatically appended to the format:  
# The "{exception}" placeholder is implicit here (at the end of the format).
log_format = "{time} - {level} - {message}"
logger.add(sys.stderr, format=log_format)
```

---
TITLE: Formatting Loguru Messages with Dynamic Padding
DESCRIPTION: Demonstrates how to dynamically format log messages in Loguru to achieve vertical alignment using padding. Illustrates two approaches: using Python's string formatting directives and implementing a custom `Formatter` class to adjust padding based on message length, ensuring consistent alignment of log components.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Dynamically formatting messages to properly align values with padding

The default formatter is unable to vertically align log messages because the length of `{name}`, `{function}` and `{line}` are not fixed.  
One workaround consists of using padding with some maximum value that should suffice most of the time. For this purpose, you can use Python's string formatting directives, like in this example:  
fmt = "{time} | {level: <8} | {name: ^15} | {function: ^15} | {line: >3} | {message}"
logger.add(sys.stderr, format=fmt)
```

---
TITLE: Testing Loguru Logs with Logot in Pytest
DESCRIPTION: Demonstrates how to unit test logs emitted by Loguru using the `logot` library and `pytest`. It configures `pytest` to capture Loguru logs and provides an example of asserting logged messages using `logot.assert_logged`.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Unit testing logs emitted by Loguru

Logging calls can be tested using [logot], a high-level log testing library with built-in support for Loguru:  
```

```plaintext
Enable Loguru log capture in your [pytest] configuration:  
```

---
TITLE: Creating Customizable Logging Levels with Loguru
DESCRIPTION: Demonstrates how to create custom logging levels in Loguru using the `level()` function, extending the standard levels like `trace()` and `success()`. This allows developers to define specific logging levels with custom names, numbers, colors, and icons for enhanced log message categorization and filtering.
SOURCE: /README.md

```python
new_level = logger.level("SNAKY", no=38, color="<yellow>", icon="🐍")

logger.log("SNAKY", "Here we go!")
```

---
TITLE: Implementing Asynchronous, Thread-Safe, Multiprocess-Safe Logging with Loguru
DESCRIPTION: Demonstrates how to implement asynchronous, thread-safe, and multiprocess-safe logging using the Loguru library by adding sinks to the `logger` with `enqueue=True`. This ensures log integrity and supports coroutine functions as sinks, which should be awaited with `complete()`.
SOURCE: /README.md

```python
logger.add("somefile.log", enqueue=True)
```

---
TITLE: Logging Function Entry and Exit with Decorators in Loguru
DESCRIPTION: Demonstrates how to log function entry, exit, and execution time using Python decorators with the `Loguru` library. This approach allows for easy tracing and debugging of function calls, including argument values, return values, and execution duration, enhancing code observability.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Logging entry and exit of functions with a decorator

In some cases, it might be useful to log entry and exit values of a function. Although Loguru doesn't provide such feature out of the box, it can be easily implemented by using Python decorators:  
```

```plaintext
You could then use it like this:  
```

```plaintext
Which would result in:  
```

```plaintext
Here is another simple example to record timing of a function:  
```

```plaintext
Finally, here is an example of a generic wrapper that combines a success message with error handling during function execution:  
```

---
TITLE: Adapting Loguru Message Colors and Format Dynamically
DESCRIPTION: Demonstrates how to customize log message colors and formatting in Loguru using markup tags and a formatting function. It illustrates associating modules with unique colors and dynamically colorizing the `record["message"]` content, ensuring proper escaping for formatting.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Adapting colors and format of logged messages dynamically

It is possible to customize the colors of your logs thanks to several {ref}`markup tags <color>`. Those are used to configure the `format` of your handler. By creating a appropriate formatting function, you can easily define colors depending on the logged message.  
For example, if you want to associate each module with a unique color:  
from collections import defaultdict
from random import choice

colors = ["blue", "cyan", "green", "magenta", "red", "yellow"]
color_per_module = defaultdict(lambda: choice(colors))

def formatter(record):
color_tag = color_per_module[record["name"]]
return "<" + color_tag + ">[{name}]</> <bold>{message}</>
{exception}"

logger.add(sys.stderr, format=formatter)
```

---
TITLE: Adding Log Handlers with `logger.add()` in Loguru
DESCRIPTION: Demonstrates how to use the `logger.add()` function in Loguru to register sinks for managing log messages, including formatting, filtering, and setting the log level; this single function provides a unified way to configure log handling without separate handlers, formatters, or filters.
SOURCE: /README.md

```python
logger.add(sys.stderr, format="{time} {level} {message}", filter="my_module", level="INFO")
```

---
TITLE: Handling f-strings and Exceptions in Loguru
DESCRIPTION: Illustrates how to handle `AttributeError` and `IndexError` exceptions when using f-strings with Loguru. Explains how to avoid unintended curly braces in log messages by using Loguru's formatting capabilities or disabling formatting, and demonstrates using `logger.bind()` for adding extra information.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## Why logging a message with f-string sometimes raises an exception?

AttributeError: 'dict' object has no attribute 'format'
logger.debug({"key": "value"}, identifier=42)
```

```plaintext
# IndexError: Replacement index 0 out of range for positional args tuple
logger.error("Use 'set()' not '{}' for empty set", strictness=9)
```

```plaintext
data = {"foo": 42}

# Will raise "KeyError" because it's equivalent to:
# logger.info("Processing '{'foo': 42}'", data=data)
logger.info(f"Processing '{data}'", data=data)
```

```plaintext
logger.info("Processing '{data}'", data=data)
```

```plaintext
logger.bind(data=data).info(f"Processing '{data}'")
```

```plaintext
logger.info("Curly brackets are {{ and }}", data=data)
```

---
TITLE: Configuring Loguru for Library and Application Usage
DESCRIPTION: Illustrates how to configure `Loguru` for use in both libraries and applications, emphasizing the importance of disabling logging in libraries by default using `logger.disable()` to avoid interfering with user application logs. It advises providing a `configure_logger()` function for library users to enable logging if desired, and outlines best practices for file structure and logging configuration within a package, including `__init__.py`, `__main__.py`, and `mymodule.py`.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Configuring Loguru to be used by a library or an application

A clear distinction must be made between the use of Loguru within a library or an application.  
In case of an application, you can add handlers from anywhere in your code. It's advised though to configure the logger from within a [if-name-equals-main] block inside the entry file of your script.  
However, if your work is intended to be used as a library, you usually should not add any handler. This is user responsibility to configure logging according to its preferences, and it's better not to interfere with that. Indeed, since Loguru is based on a single common logger, handlers added by a library will also receive user logs, which is generally not desirable.  
By default, a third-library should not emit logs except if specifically requested. For this reason, there exist the {{ disable }} and {{ enable }} methods. Make sure to first call `logger.disable("mylib")`. This avoids library logs to be mixed with those of the user. The user can always call `logger.enable("mylib")` if he wants to access the logs of your library.  
If you would like to ease logging configuration for your library users, it is advised to provide a function like `configure_logger()` in charge of adding the desired handlers. This will allow the user to activate the logging only if he needs to.  
To summarize, let's look at this hypothetical package (none of the listed files are required, it all depends on how you plan your project to be used):  
```

---
TITLE: Implementing Changes and Contributing to Loguru
DESCRIPTION: Details the process for implementing changes and contributing to the `Loguru` library, including forking the repository, setting up a development environment with `venv` and `pip install -e ".[dev]"`, and installing `pre-commit` hooks. This workflow ensures code quality and consistency when submitting pull requests.
SOURCE: /CONTRIBUTING.rst

```plaintext
$ git clone git@github.com:your_name_here/loguru.git
$ cd loguru
```

```plaintext
$ python -m venv env
$ source env/bin/activate
```

```plaintext
05. Install pre-commit hooks that will check your commits:  
```

```plaintext
06. Create a new branch from `master`:  
$ git checkout master
$ git branch fix_bug
$ git checkout fix_bug
```

---
TITLE: Adding Custom Logging Levels and Functions in Loguru
DESCRIPTION: Demonstrates how to add custom logging levels to the `logger` in Loguru and create corresponding logging functions using `partialmethod`. This allows for convenient and reusable logging with custom levels, ensuring the new method remains available even after using `logger.bind()`, `logger.patch()`, and `logger.opt()`.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Using logging function based on custom added levels

After adding a new level, it's habitually used with the {{ log }} function:  
```

```plaintext
For convenience, one can assign a new logging function which automatically uses the custom added level:  
```

---
TITLE: Handling Loguru RuntimeError: Deadlock Avoided
DESCRIPTION: Demonstrates how to prevent `RuntimeError` caused by deadlock avoidance in Loguru when logging functions are called recursively. Implements a `filter` to avoid recursive calls to the logger within handlers, ensuring the logger is not used when it's already in use in the same thread.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## How do I prevent "RuntimeError" due to "deadlock avoided"?

The logging functions are not reentrant. This means you must not use the logger when it's already in use in the same thread. This situation can occur notably if you use the logger inside a sink (which itself is called by the logger). Logically, this would result in an infinite recursive loop. In practice, it would more likely cause your application to hang because logging is protected by an internal lock.  
To prevent such problems, there is a mechanism that detects and prevents the logger from being called recursively. This is what might lead to a `RuntimeError`. When faced with such an error, you need to ensure that the handlers you configure do not internally call the logger. This also applies to the logger from the standard `logging` library.  
If you cannot prevent the use of the logger inside a handler, you should implement a `filter` to avoid recursive calls. For example:  
import sys
from loguru import logger

def my_sink(message):
logger.debug("Within my sink")
print(message, end="")

def avoid_recursion(record):
return record["function"] != "my_sink"

if __name__ == "__main__":
logger.remove()
logger.add("file.log")
logger.add(my_sink, filter=avoid_recursion)

logger.info("First message")
logger.debug("Another message")
```

---
TITLE: Capturing Standard Output, Error, and Warnings with Loguru
DESCRIPTION: Demonstrates how to capture standard `stdout` and `stderr` streams using `contextlib.redirect_stdout` with Loguru, allowing logging of output from code outside direct control. Also illustrates capturing warnings emitted by an application by replacing `warnings.showwarning` to route warning messages through the Loguru logger.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Capturing standard `stdout`, `stderr` and `warnings`

The use of logging should be privileged over {{ print }}, yet, it may happen that you don't have plain control over code executed in your application. If you wish to capture standard output, you can suppress {{ sys.stdout }} (and {{ sys.stderr }}) with a custom stream object using {{ contextlib.redirect_stdout }}. You have to take care of first removing the default handler, and not adding a new stdout sink once redirected or that would cause dead lock (you may use {{ sys.__stdout__ }} instead):  
```

```plaintext
You may also capture warnings emitted by your application by replacing {{ warnings.showwarning }}:  
```

```plaintext
Alternatively, if you want to emit warnings based on logged messages, you can simply use {{ warnings.warn }} as a sink:  
```

---
TITLE: Exploring Loguru Logger API Reference
DESCRIPTION: Presents the `loguru` library's core API, focusing on the `Logger` class and its methods like `add`, `remove`, `catch`, and logging levels. It details how to configure and use the logger for various logging functionalities, including sinks, message formatting, and exception handling.
SOURCE: /docs/api.rst

```plaintext
```{toctree}
:hidden: true
:includehidden: true

api/logger.rst
api/type_hints.rst
```

---
TITLE: Handling Multiprocessing Compatibility with Loguru `enqueue` Argument
DESCRIPTION: Illustrates how to use the `enqueue` argument in Loguru to ensure compatibility with the `multiprocessing` module, especially on Windows where forking is not supported. Demonstrates passing the `logger` object to child processes and using `initializer` and `initargs` with `Pool` to share the logger in a picklable way, addressing issues with handler inheritance and pickling requirements.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Compatibility with `multiprocessing` using `enqueue` argument

On Linux, thanks to {{ os.fork }} there is no pitfall while using the `logger` inside another process started by the {{ multiprocessing }} module. The child process will automatically inherit added handlers, the `enqueue=True` parameter is optional but is recommended as it would avoid concurrent access of your sink:  
# Linux implementation
import multiprocessing
from loguru import logger

def my_process():
logger.info("Executing function in child process")
logger.complete()

if __name__ == "__main__":
logger.add("file.log", enqueue=True)

process = multiprocessing.Process(target=my_process)
process.start()
process.join()

logger.info("Done")
```

```plaintext
Windows requires the added sinks to be picklable or otherwise will raise an error while creating the child process. Many stream objects like standard output and file descriptors are not picklable. In such case, the `enqueue=True` argument is required as it will allow the child process to only inherit the queue object where logs are sent.  
The {{ multiprocessing }} library is also commonly used to start a pool of workers using for example {{ Pool.map }} or {{ Pool.apply }}. Again, it will work flawlessly on Linux, but it will require some tinkering on Windows. You will probably not be able to pass the `logger` as an argument for your worker functions because it needs to be picklable, but although handlers added using `enqueue=True` are "inheritable", they are not "picklable". Instead, you will need to make use of the `initializer` and `initargs` parameters while creating the {{ Pool }} object in a way allowing your workers to access the shared `logger`. You can either assign it to a class attribute or override the global logger of your child processes:  
# workers_a.py
class Worker:

_logger = None

@staticmethod
def set_logger(logger_):
Worker._logger = logger_

def work(self, x):
self._logger.info("Square rooting {}", x)
return x**0.5
```

```plaintext
# workers_b.py
from loguru import logger

def set_logger(logger_):
global logger
logger = logger_

def work(x):
logger.info("Square rooting {}", x)
return x**0.5
```

```plaintext
# main.py
from multiprocessing import Pool
from loguru import logger
import workers_a
import workers_b

if __name__ == "__main__":
logger.remove()
logger.add("file.log", enqueue=True)

worker = workers_a.Worker()
with Pool(4, initializer=worker.set_logger, initargs=(logger, )) as pool:
results = pool.map(worker.work, [1, 10, 100])

with Pool(4, initializer=workers_b.set_logger, initargs=(logger, )) as pool:
results = pool.map(workers_b.work, [1, 10, 100])

logger.info("Done")
```

---
TITLE: Using the `loguru.logger` API for Logging
DESCRIPTION: Defines the `loguru.logger` API, providing access to the `Logger` class for structured logging. This module allows developers to configure and utilize the Loguru logging library for enhanced debugging and monitoring capabilities.
SOURCE: /docs/api/logger.rst

```plaintext
```{eval-rst}
.. autoclass:: loguru._logger.Logger()
:members:
```

---
TITLE: Setting Logging Level with Loguru Handlers
DESCRIPTION: Demonstrates how to set the logging level for Loguru handlers using the `level` argument of the `add` method to filter messages based on importance. Explains how to modify the logging level by removing an existing handler with `remove` and adding a new one, as it's not possible to change the level of an existing handler directly.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## How do I set the logging level?

The {ref}`logging levels <levels>` allow filtering messages based on their importance. It is a minimum threshold above which messages are logged (or ignored otherwise). This makes it possible, for example, to adjust the verbosity of logs depending on the execution environment (development or production).  
The {{ Logger }} itself is not associated with any specific level. Instead, it is the level of each handler that individually determines whether a message is logged or not. This level is defined when configuring the handler and adding it to the logger using the `level` argument of the {{ add }} method:  
logger.add(sys.stdout, level="WARNING")  # Log only messages with level "WARNING" or higher.
logger.debug("Some debug message")  # Will be ignored.
logger.error("Some error message")  # Will be displayed.
```

```plaintext
logger.remove()  # Remove the default handler.
logger.add(sys.stderr, level="INFO")
```

---
TITLE: Serializing Loguru Messages with Custom Functions
DESCRIPTION: Demonstrates how to serialize log messages in Loguru using custom functions instead of the built-in `serialize` parameter, allowing for tailored JSON output for specific sinks. This approach is useful when needing to modify the generated JSON string or when integrating with systems requiring specific data formats.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Serializing log messages using a custom function

Each handler added with `serialize=True` will create messages by converting the logging record to a valid JSON string. Depending on the sink for which the messages are intended, it may be useful to make changes to the generated string. Instead of using the `serialize` parameter, you can implement your own serialization function and use it directly in your sink:  
def serialize(record):
subset = {"timestamp": record["time"].timestamp(), "message": record["message"]}
return json.dumps(subset)

def sink(message):
serialized = serialize(message.record)
print(serialized)

logger.add(sink)
```

```plaintext
You can also use {{ patch }} for this, so the serialization function will be called only once in case you want to use it in multiple sinks:  
```

---
TITLE: Replacing `assertLogs()` with Loguru for Testing
DESCRIPTION: Demonstrates how to replace the standard library's `unittest.assertLogs()` method with a custom context manager for capturing and testing Loguru-based logs. This approach allows developers to verify logged messages and their attributes when using Loguru for logging in their applications.
SOURCE: /docs/resources/migration.rst

```plaintext

## Replacing `assertLogs()` method from `unittest` library

The {{ assertLogs }} method defined in the {{ unittest }} from standard library is used to capture and test logged messages. However, it can't be made compatible with Loguru. It needs to be replaced with a custom context manager possibly implemented as follows:  
```

```plaintext
It provides the list of {ref}`logged messages <message>` for each of which you can access {ref}`the record attribute<record>`. Here is a usage example:  
def do_something(val):
if val < 0:
logger.error("Invalid value")
return 0
return val * 2

class TestDoSomething(unittest.TestCase):
def test_do_something_good(self):
with capture_logs() as output:
do_something(1)
self.assertEqual(output, [])

def test_do_something_bad(self):
with capture_logs() as output:
do_something(-1)
self.assertEqual(len(output), 1)
message = output[0]
self.assertIn("Invalid value", message)
self.assertEqual(message.record["level"].name, "ERROR")
```

---
TITLE: Handling Datetime Formatting with Loguru
DESCRIPTION: Demonstrates improved datetime handling in Loguru, addressing issues like naive datetimes and unintuitive formatting. It configures the `logger.add` function with a custom format string, enabling precise control over the `time`, `level`, and `message` attributes in log entries.
SOURCE: /README.md

```python
logger.add("file.log", format="{time:YYYY-MM-DD at HH:mm:ss} | {level} | {message}")
```

---
TITLE: Formatting Strings Using Braces Style with Loguru
DESCRIPTION: Demonstrates modern string formatting in Loguru using the `{}` style, equivalent to `str.format()`. This approach offers a more elegant and powerful alternative to `%` formatting, allowing for named placeholders and improved readability.
SOURCE: /README.md

```python
logger.info("If you're using Python {}, prefer {feature} of course!", 3.6, feature="f-strings")
```

---
TITLE: Handling ValueError: I/O Operation on Closed File in Loguru
DESCRIPTION: Illustrates how to handle the `ValueError: I/O operation on closed file` error in Loguru, which occurs when the logger attempts to write to a closed stream like `sys.stdout` or `sys.stderr`. This often happens when third-party tools or environments replace standard streams, and the solution involves re-initializing the logger or dynamically retrieving the stream using `logger.add(lambda m: sys.stdout.write(m))`.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## How do I fix "ValueError: I/O operation error on closed file"?

This error occurs because the logger is trying to write to a stream object (like `sys.stderr` or `sys.stdout`) that has been closed, which is invalid (see {{ IOBase.close }}).  
When stream objects are used as logging sink, Loguru will not close them. This would be very inconvenient and incorrect (as the stream is global, it must remain usable after the sink has been removed). Since Loguru does not close such a stream by itself, this means something else closed the stream while it was still in use by the `logger`.  
This is generally due to some tools or specific environments that take the liberty of replacing `sys.stdout` and `sys.stderr` with their own stream object. In this way, they can capture what is written to the standard output. This is the case with some libraries, IDEs and cloud platforms.
The problem is that the `logger` will use this wrapped stream as well. If the third-party tool happens to clean up and close the stream, then the `logger` is left with an unusable sink.  
Here is a simplified example to illustrate the issue:  
```

```plaintext
And here is another example causing the same error with Pytest:  
```

---
TITLE: Logging Out-of-the-Box with Pre-configured `logger`
DESCRIPTION: Demonstrates using the pre-configured `logger` from the Loguru library for immediate logging to `stderr` without boilerplate. This allows for quick and simple logging implementation, dispatching messages to configured handlers.
SOURCE: /README.md

```python
from loguru import logger

logger.debug("That's it, beautiful and simple logging!")
```

---
TITLE: Implementing Lazy Evaluation with `opt()` in Loguru
DESCRIPTION: Demonstrates lazy evaluation of expensive functions using the `opt(lazy=True)` method in Loguru to avoid performance penalties. Illustrates additional usages of `opt()` for exception handling, colored logs, accessing record data, bypassing formatting, adjusting stack depth, and controlling keyword argument capture.
SOURCE: /README.md

```python
logger.opt(lazy=True).debug("If sink level <= DEBUG: {x}", x=lambda: expensive_function(2**64))

# By the way, "opt()" serves many usages
logger.opt(exception=True).info("Error stacktrace added to the log message (tuple accepted too)")
logger.opt(colors=True).info("Per message <blue>colors</blue>")
logger.opt(record=True).info("Display values from the record (eg. {record[thread]})")
logger.opt(raw=True).info("Bypass sink formatting
")
logger.opt(depth=1).info("Use parent stack context (useful within wrapped functions)")
logger.opt(capture=False).info("Keyword arguments not added to {dest} dict", dest="extra")
```

---
TITLE: Integrating Loguru Logging with `tqdm` Progress Bars
DESCRIPTION: Demonstrates how to integrate `loguru` logging with `tqdm` progress bars to avoid disturbing the displayed progress. It uses `tqdm.write()` instead of writing logs directly to `sys.stderr`, and addresses potential colorization issues with `tqdm` on Windows by calling `colorama.deinit()`.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Interoperability with `tqdm` iterations

Trying to use the Loguru's `logger` during an iteration wrapped by the `tqdm` library may disturb the displayed progress bar. As a workaround, one can use the `tqdm.write()` function instead of writings logs directly to `sys.stderr`:  
import time

from loguru import logger
from tqdm import tqdm

logger.remove()
logger.add(lambda msg: tqdm.write(msg, end=""), colorize=True)

logger.info("Initializing")

for x in tqdm(range(100)):
logger.info("Iterating #{}", x)
time.sleep(0.1)
```

---
TITLE: Installing Loguru for Python Logging
DESCRIPTION: Installs the `loguru` package using `pip`, enabling enhanced logging capabilities in Python projects. This provides a simple and effective way to manage logs, making debugging and monitoring easier.
SOURCE: /README.md

```plaintext
pip install loguru
```

---
TITLE: Displaying Stack Traces Without Error Context in Loguru
DESCRIPTION: Demonstrates how to display stack traces within Loguru without relying on an error context, useful for debugging and tracing code execution. It illustrates patching the logger to include stack trace information in log messages using the `traceback` module, enabling developers to track the call stack at specific points in their code.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Displaying a stacktrace without using the error context

It may be useful in some cases to display the traceback at the time your message is logged, while no exceptions have been raised. Although this feature is not built-in into Loguru as it is more related to debugging than logging, it is possible to {{ patch }} your logger and then display the stacktrace as needed (using the {{ traceback }} module):  
```

```plaintext
Here is another example that demonstrates how to prefix the logged message with the full call stack:  
```

---
TITLE: Handling Security Considerations when Using Loguru
DESCRIPTION: Addresses security vulnerabilities when using the `Loguru` library, including pickle deserialization attacks, format string vulnerabilities, and log injection. Demonstrates how to mitigate these risks by using HMAC for data integrity, avoiding user-controlled format strings, escaping user input, disabling diagnose mode in production, and setting appropriate file permissions.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Security considerations when using Loguru

Firstly, if you use {{ pickle }} to load log messages (e.g. from the network), make sure the source is trustable or sign the data to verify its authenticity before deserializing it. If you do not take these precautions, malicious code could be executed by an attacker. You can read more details in this article: [What’s so dangerous about pickles?](https://intoli.com/blog/dangerous-pickles/)  
```

```plaintext
You should also avoid logging a message that could be maliciously hand-crafted by an attacker. Calling `logger.debug(message, value)` is roughly equivalent to calling `print(message.format(value))` and the same safety rules apply. In particular, an attacker could force printing of assumed hidden variables of your application. Here is an article explaining the possible vulnerability: [Be Careful with Python's New-Style String Format](https://lucumr.pocoo.org/2016/12/29/careful-with-str-format/).  
SECRET_KEY = 'Y0UC4NTS33Th1S!'

class SomeValue:
def __init__(self, value):
self.value = value

# If user types "{value.__init__.__globals__[SECRET_KEY]}" then the secret key is displayed.
message = "[Custom message] " + input()
logger.info(message, value=SomeValue(10))
```

```plaintext
logger.add("file.log", format="{level} {message}")

# If value is "Josh logged in.
INFO User James" then there will appear to be two log entries.
username = external_data()
logger.info("User " + username + " logged in.")
```

```plaintext
Another thing you should consider is to change the access permissions of your log file. Loguru creates files using the built-in {{ open }} function, which means by default they might be read by a different user than the owner. If this is not desirable, be sure to modify the default access rights.  
```

---
TITLE: Using Loguru `logger` in a Cython Module
DESCRIPTION: Illustrates how to use Loguru's `logger` within a Cython module, addressing potential issues with incomplete logs due to Cython's optimization techniques that suppress stack frames. Explains how to update the default `format` or patch the `logger` to manually add contextual information when the frame is unavailable, improving log clarity.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Using Loguru's `logger` within a Cython module

Loguru and Cython do not interoperate very well. This is because Loguru (and logging generally) heavily relies on Python stack frames while Cython, being an alternative Python implementation, try to get rid of these frames for optimization reasons.  
Calling the `logger` from code compiled with Cython may result in "incomplete" logs (missing call context):  
```

```plaintext
This happens when Loguru tries to access a stack frame which has been suppressed by Cython. In such a case, there is no way for Loguru to retrieve contextual information of the logged message.  
You can update the default `format` of your handlers and omit the uninteresting fields. You can also tries to {{ patch }} the `logger` to manually add information you may know about the caller, for example:  
logger = logger.patch(lambda record: record.update(name="my_cython_module"))
```

---
TITLE: Replacing Standard Logging's `addLevelName()` and `getLevelName()` with Loguru
DESCRIPTION: Demonstrates how to replace standard logging's `addLevelName()` and `getLevelName()` functions with Loguru's `logger.level()` function for adding and retrieving custom log levels. This approach allows defining custom levels with names, numbers, colors, and icons, offering more flexibility than standard logging.
SOURCE: /docs/resources/migration.rst

```plaintext

## Replacing `addLevelName()` and `getLevelName()` functions

To add a new custom level, you can replace {{ addLevelName }} with the {{ level }} function:  
```

```plaintext
The same function can be used to replace {{ getLevelName }}:  
```

---
TITLE: Setting File Permissions Using `opener` with Loguru
DESCRIPTION: Demonstrates how to set specific file permissions when creating log files with Loguru using the `opener` argument. This allows control over file access, such as restricting access to the owner only, while considering the impact of the OS `umask` value.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Setting permissions on created log files

To set desired permissions on created log files, use the `opener` argument to pass in a custom opener with permissions octal:  
def opener(file, flags):
return os.open(file, flags, 0o600)  # read/write by owner only

logger.add("foo.log", rotation="100 kB", opener=opener)
```

---
TITLE: Creating Independent Loggers with Separate Handlers in Loguru
DESCRIPTION: Demonstrates how to create independent `logger` objects in Loguru with separate handlers using `copy.deepcopy` to avoid shared handlers and potential slowdowns from excessive filtering. This is useful when you need to route specific messages to specific handlers based on identifiers, such as task IDs, and want to avoid pickling errors by removing handlers before copying.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Creating independent loggers with separate set of handlers

Loguru is fundamentally designed to be usable with exactly one global `logger` object dispatching logging messages to the configured handlers. In some circumstances, it may be useful to have specific messages logged to specific handlers.  
For example, supposing you want to split your logs in two files based on an arbitrary identifier, you can achieve that by combining {{ bind }} and `filter`:  
from loguru import logger

def task_A():
logger_a = logger.bind(task="A")
logger_a.info("Starting task A")
do_something()
logger_a.success("End of task A")

def task_B():
logger_b = logger.bind(task="B")
logger_b.info("Starting task B")
do_something_else()
logger_b.success("End of task B")

logger.add("file_A.log", filter=lambda record: record["extra"]["task"] == "A")
logger.add("file_B.log", filter=lambda record: record["extra"]["task"] == "B")

task_A()
task_B()
```

---
TITLE: Customizing Log Format and Reusing Default in Loguru
DESCRIPTION: Demonstrates how to customize the log format using the `format` argument in `logger.add()` within Loguru, including using formatting variables, color tags, and custom formatting functions. It explains how to redefine the default logging format by referencing the `LOGURU_FORMAT` variable in the source code.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## How do I customize the log format and re-use the default one?

The log format must be defined using the `format` argument of the {{ add }} method:  
logger.add(sys.stderr, format="{time} - {level} - {message}")
```

```plaintext
For advanced configuration, the `format` argument also accepts a function, allowing you to dynamically generate the desired format. Be aware that in this case, you have to explicitly include the line ending and exception field (since you gain full control over the formatting, while `"
{exception}"` is added automatically when the `format` is a string). For example, to include the thread identifier but only for error messages and above:  
def custom_formatter(record):
if record["level"].no >= 40:
return "<green>{time}</> - {level} - <red>{thread}</> - <lvl>{message}</>
{exception}"
else:
return "<green>{time}</> - {level} - <lvl>{message}</lvl>
{exception}"

logger.add(sys.stderr, format=custom_formatter)
```

---
TITLE: Implementing Colored Logging with Loguru
DESCRIPTION: Demonstrates how to add colored output to logs using Loguru. It configures the `logger` to output to `sys.stdout` with colorization enabled and a custom format string using markup tags for styling, enhancing log readability.
SOURCE: /README.md

```python
logger.add(sys.stdout, colorize=True, format="<green>{time}</green> <level>{message}</level>")
```

---
TITLE: Customizing Exception Formatting in Loguru
DESCRIPTION: Demonstrates customizing the formatting of exceptions using `logger.add` in Loguru. This allows developers to control how exception information, including traceback details and error messages, is displayed in log outputs, enhancing debugging and error analysis.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Customizing the formatting of exceptions

logger.add(sys.stderr, format=format)
```

```none
2019-11-15T10:46:18.059964+0100 Oups...
File foo.py, line 17, in inverse
15   def inverse(x):
16       try:
--> 17           1 / x
18       except ZeroDivisionError:
..................................................
x = 0
..................................................

ZeroDivisionError: division by zero
```

---
TITLE: Troubleshooting Incorrect Source Information in Loguru Logs
DESCRIPTION: Explains why Loguru log messages might display incorrect or missing source information (name, file, function, line). It details scenarios involving `Dask` or `Cython` and suggests using a custom `patch` function or adjusting the `depth` argument of the `opt` method to resolve the issue.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## Why is the source (name, file, function, line) of the log message incorrect or missing?

In some very specific circumstances, the module name might be `None` and the filename and function name might be `"<unknown>"`.  
```

```plaintext
Such a situation indicates that the `logger` was unable to retrieve the caller's context. In particular, this can happen when Loguru is used with Dask or Cython. In such cases, this behavior is normal, and there is nothing to do unless you wish to implement a custom {{ patch }} function:  
logger = logger.patch(lambda record: record.update(name="my_module"))
```

---
TITLE: Changing Loguru Handler Level by Removing and Adding
DESCRIPTION: Demonstrates how to change the logging level of an existing Loguru handler by removing the handler using `logger.remove(handler_id)` and then re-adding it with `logger.add()` and the updated `level` parameter. Alternatively, it illustrates using the `filter` argument with the `bind` method to dynamically filter logs based on their level, providing more advanced control over handler's level.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Changing the level of an existing handler

Once a handler has been added, it is actually not possible to update it. This is a deliberate choice in order to keep the Loguru's API minimal. Several solutions are possible, though, if you need to change the configured `level` of a handler. Chose the one that best fits your use case.  
The most straightforward workaround is to {{ remove }} your handler and then re-{{ add }} it with the updated `level` parameter. To do so, you have to keep a reference to the identifier number returned while adding a handler:  
handler_id = logger.add(sys.stderr, level="WARNING")

logger.info("Logging 'WARNING' or higher messages only")

...

logger.remove(handler_id)  # For the default handler, it's actually '0'.
logger.add(sys.stderr, level="DEBUG")

logger.debug("Logging 'DEBUG' messages too")
```

```plaintext
Finally, more advanced control over handler's level can be achieved by using a callable object as the `filter`:  
min_level = logger.level("DEBUG").no

def filter_by_level(record):
return record["level"].no >= min_level

logger.remove()
logger.add(sys.stderr, filter=filter_by_level, level=0)

logger.debug("Logged")

min_level = logger.level("WARNING").no

logger.debug("Not logged")
```

---
TITLE: Customizing Loguru Defaults Using Environment Variables
DESCRIPTION: Demonstrates how to personalize default settings in `Loguru` using environment variables. This allows modification of the logger's format and debug color, enabling users to tailor the logging behavior without modifying the code.
SOURCE: /README.md

```bash
# Linux / OSX
export LOGURU_FORMAT="{time} | <lvl>{message}</lvl>"

# Windows
setx LOGURU_DEBUG_COLOR "<green>"
```

---
TITLE: Implementing Changes and Contributing to Loguru
DESCRIPTION: Details the process of implementing changes to the `Loguru` library, including writing unit tests with `tox`, updating documentation and the `CHANGELOG.rst` file, and using `git` for committing and pushing changes. It also covers pre-commit hooks and opening a pull request for review and merging.
SOURCE: /CONTRIBUTING.rst

```plaintext
$ tox -e tests
```

---
TITLE: Transmitting Loguru Messages Across Network and Processes
DESCRIPTION: Demonstrates how to transmit log messages across a network between processes using `loguru` by serializing log records with `pickle` and sending them over TCP sockets. This approach is useful when sharing a logger between processes is not possible, such as in Gunicorn workers, ensuring the integrity of logged messages by using a dedicated server to handle TCP requests.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Transmitting log messages across network, processes or Gunicorn workers

It is possible to send and receive logs between different processes and even between different computers if needed. Once the connection is established between the two Python programs, this requires serializing the logging record in one side while re-constructing the message on the other hand. Keep in mind though that [pickling is unsafe](https://intoli.com/blog/dangerous-pickles/), you should use this with care.  
The first thing you will need is to run a server responsible for receiving log messages emitted by other processes:  
```

```plaintext
Then, you need your clients to send messages using a specific handler:  
```

```plaintext
Make sure that the server is running while the clients are logging messages, and note that they must communicate on the same port.  
Another example, when using Gunicorn and FastAPI you should add the previously defined `SocketHandler` to each of the running workers, possibly like so:  
from contextlib import asynccontextmanager
from fastapi import FastAPI
from loguru import logger

@asynccontextmanager
async def lifespan(app: FastAPI):
"""Setup the server instance (executed once for each worker)."""
logger.configure(handlers=[{"sink": SocketHandler("localhost", 9999)}])
logger.debug("Worker is initializing")
yield

app = FastAPI(lifespan=lifespan)
```

---
TITLE: Integrating Loguru with Standard Python Logging
DESCRIPTION: Demonstrates how to integrate `Loguru` with Python's standard `logging` module by using `Handler` classes to both send `Loguru` messages to standard logging and intercept standard `logging` messages for `Loguru` sinks, enabling unified logging management.
SOURCE: /README.md

```python
handler = logging.handlers.SysLogHandler(address=('localhost', 514))
logger.add(handler)
```

```plaintext
Want to intercept standard `logging` messages toward your Loguru sinks?  
class InterceptHandler(logging.Handler):
def emit(self, record: logging.LogRecord) -> None:
# Get corresponding Loguru level if it exists.
try:
level: str | int = logger.level(record.levelname).name
except ValueError:
level = record.levelno

# Find caller from where originated the logged message.
frame, depth = inspect.currentframe(), 0
while frame:
filename = frame.f_code.co_filename
is_logging = filename == logging.__file__
is_frozen = "importlib" in filename and "_bootstrap" in filename
if depth > 0 and not (is_logging or is_frozen):
break
frame = frame.f_back
depth += 1

logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())

logging.basicConfig(handlers=[InterceptHandler()], level=0, force=True)
```

---
TITLE: Filtering Log Messages by Module in Loguru
DESCRIPTION: Illustrates how to differentiate log messages from different modules using Loguru's filtering capabilities and the `record["name"]` field. Demonstrates using `logger.add` with filters and the `bind` method for more precise log identification based on module origin, enabling targeted logging configurations.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## How can I use different loggers in different modules of my application?

Since Loguru is designed on the use of a single `logger`, it is fundamentally not possible to create different loggers for multiple modules. The idea is that modules should simply import the global `logger` from `loguru`, and log differentiation should be handled through handlers (which should only be configured once, at the application's entry point).  
Note that is generally possible to identify the origin of a log message via the `record["name"]` field in the record dict. This field contains the name of the module that emitted the message. For example, you can use this information to redirect messages based on their origin:  
logger.add("my_app.log")  # All messages.
logger.add("module_1.log", filter="module_1")  # Messages from "module_1" only.
logger.add("module_2.log", filter="module_2")  # Messages from "module_2" only.
```

---
TITLE: Logging Multiple Messages on the Same Line with Loguru
DESCRIPTION: Demonstrates how to log multiple messages on the same line using Loguru by manipulating the newline terminator with `bind`, `opt`, and a custom `format` function. This is useful for illustrating step-by-step processes, but may not be appropriate for all sinks.
SOURCE: /docs/resources/recipes.rst

```plaintext

## Manipulating newline terminator to write multiple logs on the same line

You can temporarily log a message on a continuous line by combining the use of {{ bind }}, {{ opt }} and a custom `format` function. This is especially useful if you want to illustrate a step-by-step process in progress, for example:  
def formatter(record):
end = record["extra"].get("end", "
")
return "[{time}] {message}" + end + "{exception}"

logger.add(sys.stderr, format=formatter)
logger.add("foo.log", mode="w")

logger.bind(end="").debug("Progress: ")

for _ in range(5):
logger.opt(raw=True).debug(".")

logger.opt(raw=True).debug("
")

logger.info("Done")
```

```none
[2020-03-26T22:47:01.708016+0100] Progress: .....
[2020-03-26T22:47:01.709031+0100] Done
```

---
TITLE: Handling Exceptions with Descriptive Stack Traces in Loguru
DESCRIPTION: Demonstrates how Loguru provides fully descriptive exceptions, including stack traces and variable values, to aid in debugging. This feature, enabled by default with `backtrace=True` and `diagnose=True` in `logger.add()`, helps identify the root cause of errors like `ZeroDivisionError` by displaying the call stack and variable states, but consider [Security considerations when using Loguru](https://loguru.readthedocs.io/en/stable/resources/recipes.html#security-considerations-when-using-loguru).
SOURCE: /README.md

```python
# Caution, "diagnose=True" is the default and may leak sensitive data in prod
logger.add("out.log", backtrace=True, diagnose=True)

def func(a, b):
return a / b

def nested(c):
try:
func(5, c)
except ZeroDivisionError:
logger.exception("What?!")

nested(0)
```

```none
2018-07-17 01:38:43.975 | ERROR    | __main__:nested:10 - What?!
Traceback (most recent call last):

File "test.py", line 12, in <module>
nested(0)
└ <function nested at 0x7f5c755322f0>

> File "test.py", line 8, in nested
func(5, c)
│       └ 0
└ <function func at 0x7f5c79fc2e18>

File "test.py", line 4, in func
return a / b
│   └ 0
└ 5

ZeroDivisionError: division by zero
```

---
TITLE: Replacing `captureWarnings()` with Loguru for Warnings Redirection
DESCRIPTION: Demonstrates how to replace the standard logging's `captureWarnings()` function with Loguru to redirect alerts from the `warnings` module. This involves replacing `warnings.showwarning` to log warning messages using Loguru's `logger.warning` function, ensuring that warnings are captured and handled within the Loguru logging system.
SOURCE: /docs/resources/migration.rst

```plaintext

## Replacing `captureWarnings()` function

The {{ captureWarnings }} function which redirects alerts from the {{ warnings }} module to the logging system can be implemented by simply replacing {{ warnings.showwarning }} function as follow:  
```

---
TITLE: Handling Logger Class Access at Runtime in Loguru
DESCRIPTION: Explains why the `Logger` class cannot be directly accessed or instantiated at runtime from the `loguru` library, and demonstrates how to use it for type hinting purposes only. Illustrates how to perform type checking at runtime by comparing the type of the `logger` instance.
SOURCE: /docs/resources/troubleshooting.rst

```plaintext

## Why can't I access the `Logger` class and other types at runtime?

The `logger` object imported from the `loguru` library is an instance of the {{ Logger }} class. However, you should not attempt to instantiate a logger yourself. The {{ Logger }} class is not public and will be unusable by your Python application. It is therefore expected that the following code will raise an error:  
from loguru import Logger
# Output: ImportError: cannot import name 'Logger' from 'loguru'
```

```plaintext
If for some reason you need to perform type checking at runtime, you can make a comparison with the type on the `logger` instance:  
import loguru
import logging

def my_function(logger: loguru.Logger | logging.Logger):
if isinstance(logger, type(loguru.logger)):
logger.info("Hello, {}!", "World")
else:
logger.info("Hello, %s!", "World")
```

---
TITLE: Replacing Handlers, Filters, and Formatters with Loguru
DESCRIPTION: Demonstrates how to replace standard `logging`'s `Handler`, `Filter`, and `Formatter` objects with Loguru's `add` method for configuring logging sinks. Loguru simplifies handler management by consolidating level setting, formatting, and filtering into the `add` method, eliminating the need for explicit thread-safety management.
SOURCE: /docs/resources/migration.rst

```plaintext

## Replacing `Handler`, `Filter` and `Formatter` objects

Standard `logging` requires you to create an {{ Handler }} object and then call {{ addHandler }}. Using Loguru, the handlers are started using {{ add }}. The sink defines how the handler should manage incoming logging messages, as would do {{ handle }} or {{ emit }}. To log from multiple modules, you just have to import the logger, all messages will be dispatched to the added handlers.  
While calling {{ add }}, the `level` parameter replaces {{ handler.setLevel }}, the `format` parameter replaces {{ setFormatter }}, the `filter` parameter replaces {{ handler.addFilter }}. The thread-safety is managed automatically by Loguru, so there is no need for {{ createLock }}, {{ acquire }} nor {{ release }}. The equivalent method of {{ removeHandler }} is {{ remove }} which should be used with the identifier returned by {{ add }}.  
Note that you don't necessarily need to replace your {{ Handler }} objects because {{ add }} accepts them as valid sinks.  
In short, you can replace:  
```

```plaintext
With:  
```

---
TITLE: Replacing `extra` Argument and `LoggerAdapter` with Loguru
DESCRIPTION: Illustrates how to replace the standard logging `extra` argument and `LoggerAdapter` objects with Loguru's `bind` method for adding contextual information to log messages. This approach simplifies passing context and requires adjusting the handler format to access the `record["extra"]` dictionary.
SOURCE: /docs/resources/migration.rst

```plaintext

## Replacing `extra` argument and `LoggerAdapter` objects

To pass contextual information to log messages, replace `extra` by inlining {{ bind }} method:  
context = {"clientip": "192.168.0.1", "user": "fbloggs"}

logger.info("Protocol problem", extra=context)   # Standard logging
logger.bind(**context).info("Protocol problem")  # Loguru
```

```plaintext
You can also replace {{ LoggerAdapter }} by calling `logger = logger.bind(clientip="192.168.0.1")` before using it, or by assigning the bound logger to a class instance:  
class MyClass:

def __init__(self, clientip):
self.logger = logger.bind(clientip=clientip)

def func(self):
self.logger.debug("Running func")
```
